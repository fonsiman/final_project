{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.3 (default, Mar 27 2019, 22:11:17) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\"0-PALM\", \"1-THUMBSUP\", \"2-VICTORY\", \"3-POINT\", \"4-ROCK\", \"5-OK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>gesture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inputs/0-PALM/B_P_hgr1_id08_1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inputs/0-PALM/B_P_hgr1_id12_2.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inputs/0-PALM/5_A_hgr2A2_id02_1.bmp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inputs/0-PALM/B_P_hgr1_id12_2.bmp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inputs/0-PALM/B_P_hgr1_id06_2.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  path gesture\n",
       "0    inputs/0-PALM/B_P_hgr1_id08_1.jpg       0\n",
       "1    inputs/0-PALM/B_P_hgr1_id12_2.jpg       0\n",
       "2  inputs/0-PALM/5_A_hgr2A2_id02_1.bmp       0\n",
       "3    inputs/0-PALM/B_P_hgr1_id12_2.bmp       0\n",
       "4    inputs/0-PALM/B_P_hgr1_id06_2.jpg       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = pd.DataFrame(columns=[\"path\", \"gesture\"])\n",
    "for folder in folders:\n",
    "    for f_name in os.listdir('inputs/'+folder):\n",
    "        images = images.append({\"path\": 'inputs/'+folder+'/'+f_name, \"gesture\": folder[0]}, ignore_index=True)\n",
    "\n",
    "        \n",
    "display(images.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(images[\"path\"][0], cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_resized = cv2.resize(img, (50,50), interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgYCC = cv2.cvtColor(img_resized, cv2.COLOR_BGR2YCR_CB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "print(imgYCC.shape)\n",
    "height, width = imgYCC.shape[:2]\n",
    "\n",
    "middle_color = imgYCC[25,25]\n",
    "y_range = 20\n",
    "cb_range = 15\n",
    "cr_range = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 30, 117, 140],\n",
       "        [ 31, 117, 141],\n",
       "        [ 33, 116, 141],\n",
       "        ...,\n",
       "        [ 22, 119, 139],\n",
       "        [ 21, 119, 139],\n",
       "        [ 21, 119, 138]],\n",
       "\n",
       "       [[ 31, 116, 141],\n",
       "        [ 33, 116, 141],\n",
       "        [ 33, 116, 142],\n",
       "        ...,\n",
       "        [ 23, 118, 139],\n",
       "        [ 22, 119, 139],\n",
       "        [ 21, 119, 138]],\n",
       "\n",
       "       [[ 32, 116, 142],\n",
       "        [ 33, 116, 142],\n",
       "        [ 33, 117, 142],\n",
       "        ...,\n",
       "        [ 24, 118, 139],\n",
       "        [ 23, 118, 139],\n",
       "        [ 22, 119, 138]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 29, 117, 140],\n",
       "        [ 29, 117, 140],\n",
       "        [ 29, 117, 140],\n",
       "        ...,\n",
       "        [ 21, 119, 138],\n",
       "        [ 19, 119, 139],\n",
       "        [ 15, 122, 135]],\n",
       "\n",
       "       [[ 29, 117, 140],\n",
       "        [ 29, 117, 140],\n",
       "        [ 29, 117, 140],\n",
       "        ...,\n",
       "        [ 19, 120, 136],\n",
       "        [ 16, 122, 135],\n",
       "        [  7, 127, 131]],\n",
       "\n",
       "       [[ 28, 117, 139],\n",
       "        [ 29, 117, 139],\n",
       "        [ 29, 117, 140],\n",
       "        ...,\n",
       "        [  7, 127, 130],\n",
       "        [  7, 127, 129],\n",
       "        [  6, 128, 129]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def processImage(path):\n",
    "    img_resized = cv2.resize(img, (100,100), interpolation = cv2.INTER_AREA)\n",
    "    imgYCC = cv2.cvtColor(img_resized, cv2.COLOR_BGR2YCR_CB)\n",
    "    height, width = imgYCC.shape[:2]\n",
    "    middle_color = imgYCC[25,25]\n",
    "    y_range = 20\n",
    "    cb_range = 15\n",
    "    cr_range = 10\n",
    "    return imgYCC\n",
    "\n",
    "def addRotations(img):\n",
    "    for angle in range(0, 360, 15):\n",
    "        rotated = imutils.rotate(img, angle)\n",
    "        cv2.imshow(\"Rotated (Problematic)\", rotated)\n",
    "        cv2.waitKey(0)\n",
    "    \n",
    "img = cv2.imread(images[\"path\"][0], cv2.IMREAD_COLOR)\n",
    "processImage(images[\"path\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"M = cv2.getRotationMatrix2D((len(img/2),len(img/2)), 45, 1)\\nrotated180 = cv2.warpAffine(img, M, (len(img/2),len(img/2))) \\n\\ncv2.imshow('Original Image',rotated180)\\ncv2.waitKey(0) # waits until a key is pressed\\ncv2.destroyAllWindows() # destroys the window showing image\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''M = cv2.getRotationMatrix2D((len(img/2),len(img/2)), 45, 1)\n",
    "rotated180 = cv2.warpAffine(img, M, (len(img/2),len(img/2))) \n",
    "\n",
    "cv2.imshow('Original Image',rotated180)\n",
    "cv2.waitKey(0) # waits until a key is pressed\n",
    "cv2.destroyAllWindows() # destroys the window showing image'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import rotate_bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(len(images)):\n",
    "    img = cv2.imread(images[\"path\"][i], cv2.IMREAD_COLOR)\n",
    "    for angle in np.arange(0, 360, 45):\n",
    "        rotated = rotate_bound(img, angle)\n",
    "        X.append(processImage(rotated))\n",
    "        y.append(images[\"gesture\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1606.4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train = X[:183]\\nX_test = X[183:]\\ny_train = y[:183]\\ny_test = y[183:]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''X_train = X[:183]\n",
    "X_test = X[183:]\n",
    "y_train = y[:183]\n",
    "y_test = y[183:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_files, te_files, tr_labels, te_labels = \\\n",
    "    train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0802 23:56:48.293644 140165801953088 deprecation_wrapper.py:119] From /home/alfonso/miniconda3/envs/final_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0802 23:56:48.302179 140165801953088 deprecation_wrapper.py:119] From /home/alfonso/miniconda3/envs/final_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0802 23:56:48.303809 140165801953088 deprecation_wrapper.py:119] From /home/alfonso/miniconda3/envs/final_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0802 23:56:48.319326 140165801953088 deprecation_wrapper.py:119] From /home/alfonso/miniconda3/envs/final_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0802 23:56:48.552001 140165801953088 deprecation_wrapper.py:119] From /home/alfonso/miniconda3/envs/final_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0802 23:56:48.552492 140165801953088 deprecation_wrapper.py:119] From /home/alfonso/miniconda3/envs/final_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg16_conv = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    ")\n",
    "model_vgg16_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step 1...\\n    % Read the image\\n    original = imread(filename);\\n    ...\\n    Step 2...\\n    % Resize the image to 50x50\\n    image_resized = imresize(original, scale);\\n    [M N Z] = size(image_resized);\\n\\n    % Initialize the output image\\n    image_out = zeros(height,width);\\n    image_out = zeros(M,N);\\n    ...\\n    Step 3...\\n    % Convert the image from RGB to YCbCr\\n    img_ycbcr = rgb2ycbcr(image_resized);\\n    Cb = img_ycbcr(:,:,2);\\n    Cr = img_ycbcr(:,:,3);\\n    ...\\n    Step 4...\\n    % Get the central color of the image\\n    % Expected the hand to be in the central of the image\\n    central_color = img_ycbcr(int32(M/2),int32(N/2),:);\\n    Cb_Color = central_color(:,:,2);\\n    Cr_Color = central_color(:,:,3);\\n    % Set the range\\n    Cb_Difference = 15;\\n    Cr_Difference = 10;\\n    ...\\n    Step 5...\\n    % Detect skin pixels\\n    [r,c,v] = find(Cb>=Cb_Color-Cr_Difference & Cb<=Cb_Color+Cb_Difference & Cr>=Cr_Color-Cr_Difference & Cr<=Cr_Color+Cr_Difference);\\n    ...\\n    Step 6...\\n    % Mark detected pixels\\n    for i=1:match_count\\n        image_out(r(i),c(i)) = 1;\\n    end\\nend'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Step 1...\n",
    "    % Read the image\n",
    "    original = imread(filename);\n",
    "    ...\n",
    "    Step 2...\n",
    "    % Resize the image to 50x50\n",
    "    image_resized = imresize(original, scale);\n",
    "    [M N Z] = size(image_resized);\n",
    "\n",
    "    % Initialize the output image\n",
    "    image_out = zeros(height,width);\n",
    "    image_out = zeros(M,N);\n",
    "    ...\n",
    "    Step 3...\n",
    "    % Convert the image from RGB to YCbCr\n",
    "    img_ycbcr = rgb2ycbcr(image_resized);\n",
    "    Cb = img_ycbcr(:,:,2);\n",
    "    Cr = img_ycbcr(:,:,3);\n",
    "    ...\n",
    "    Step 4...\n",
    "    % Get the central color of the image\n",
    "    % Expected the hand to be in the central of the image\n",
    "    central_color = img_ycbcr(int32(M/2),int32(N/2),:);\n",
    "    Cb_Color = central_color(:,:,2);\n",
    "    Cr_Color = central_color(:,:,3);\n",
    "    % Set the range\n",
    "    Cb_Difference = 15;\n",
    "    Cr_Difference = 10;\n",
    "    ...\n",
    "    Step 5...\n",
    "    % Detect skin pixels\n",
    "    [r,c,v] = find(Cb>=Cb_Color-Cr_Difference & Cb<=Cb_Color+Cb_Difference & Cr>=Cr_Color-Cr_Difference & Cr<=Cr_Color+Cr_Difference);\n",
    "    ...\n",
    "    Step 6...\n",
    "    % Mark detected pixels\n",
    "    for i=1:match_count\n",
    "        image_out(r(i),c(i)) = 1;\n",
    "    end\n",
    "end'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"imagen\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"imagen\", img)\n",
    "cv2.resizeWindow(\"imagen\", 1200, 600);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), interpolation='bicubic')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.axvline(img.shape[1] / 2, c='r', linewidth=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "\n",
    "model=models.Sequential()\n",
    "model.add(layers.Conv2D(32, (5, 5), strides=(2, 2), activation='relu', input_shape=(100,100,3))) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu')) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(Dropout(0.25, seed=21))\n",
    "model.add(layers.Dense(128, activation='sigmoid'))\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_files, te_files, tr_labels, te_labels\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator()\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(np.array(tr_files), to_categorical(tr_labels), epochs=100, batch_size=64, verbose=1,\\\n",
    "          validation_data=(np.array(te_files), to_categorical(te_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(te_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[loss, acc] = model.evaluate(np.array(te_files), to_categorical(te_labels),verbose=1)\n",
    "print(\"Accuracy:\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes((np.array(te_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_names = {0: 'palm',\n",
    "                 1: 'thumb',\n",
    "                 2: 'victory',\n",
    "                 3: 'index',\n",
    "                 4: 'rock',\n",
    "                 5: 'oke'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "incorrect = 0\n",
    "for each in predicctions:\n",
    "    if gesture_names[each] == 'index':\n",
    "        correct +=1\n",
    "    else:\n",
    "        incorrect +=1\n",
    "print(correct, incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''THRESHOLD = 0.8\n",
    "\n",
    "class_names = {0: 'Palma',\n",
    "              1: 'Thumb', 2: 'Victoria', 3: 'Ãndice', 4: 'Rock&Roll', 5: 'OK'}\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    '''model.setInput(cv2.dnn.blobFromImage(frame, size=(300, 300), swapRB=True))'''\n",
    "    \n",
    "    output = model.forward()[0,0,:,:]\n",
    "    \n",
    "    for detection in output:\n",
    "        confidence = detection[2]\n",
    "        if confidence > THRESHOLD:\n",
    "            class_id = detection[1]\n",
    "            class_name = class_names[class_id]\n",
    "            # print(confidence, class_name)\n",
    "            \n",
    "            # rectangles!\n",
    "            \n",
    "            box_x=detection[3]\n",
    "            box_y=detection[4]\n",
    "            box_width=detection[5]\n",
    "            box_height=detection[6]\n",
    "            \n",
    "            height, width, ch = frame.shape\n",
    "            \n",
    "            box_x = detection[3] * width\n",
    "            box_y = detection[4] * height\n",
    "            box_width = detection[5] * width\n",
    "            box_height = detection[6] * height\n",
    "                                          \n",
    "            cv2.rectangle(frame, \n",
    "                          (int(box_x),\n",
    "                           int(box_y)),\n",
    "                          (int(box_width),\n",
    "                           int(box_height)),\n",
    "                          (0, 0, 255), \n",
    "                          thickness=2)\n",
    "            \n",
    "            cv2.putText(frame, \n",
    "                        class_name + ' ' + str(round(confidence, 2)),\n",
    "                        (int(box_x), \n",
    "                         int(box_y+.05*height)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,\n",
    "                        (0, 0, 255))\n",
    "    \n",
    "    cv2.imshow('object_detection', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
